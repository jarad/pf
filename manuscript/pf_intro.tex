\documentclass{elsarticle}

\usepackage{amsmath}
\usepackage{natbib}
\usepackage{color}
\usepackage{graphicx}
\usepackage{caption}

\graphicspath{{/Users/niemi/Dropbox/SIR_Particle_Filtering/Graphs/}
                       {/Users/niemi/Dropbox/SIR_Particle_Filtering/doesnotexist/}
                       {/Users/Danny/Dropbox/SIR_Particle_Filtering/Graphs/}
                       {/data/home/faculty/meiring/Dropbox/SIR_Particle_Filtering/Graphs/}
                       {./Graphs/}
                       % Add your directories here
}

\newcommand{\jarad}[1]{{\color{red}JARAD: #1}}
\newcommand{\danny}[1]{{\color{blue}DANNY: #1}}

\begin{document}

\noindent {\bf Abstract} \\

This paper reviews sequential Monte Carlo (i.e. particle filtering) methods of estimation and compares the performance of different particle filtering algorithms when applied to a stochastic compartmental model of a disease outbreak.  In addition, we compare different choices of resampling scheme and prior distribution on the unknown, fixed parameter when running the particle filter.  Our results indicate that an algorithm that resamples values of the unknown parameter using a normal kernel density approximation of the posterior performs most efficiently, is best at avoiding particle degeneracy, and enhances our ability to accurately track the evolution of an epidemic over time.

\section{Introduction} \label{sec:intro}

% Introduce Bayesian framework, MCMC
In statistical applications where it is necessary to incorporate prior knowledge of unknown quantities, the Bayesian framework is often convenient for performing statistical analysis.  In this case, all inference is conducted through the posterior distribution of the unknown quantites given the observed data.  However, the calculation of the posterior distribution can involve complicated integrals, and in many situations it is impossible to obtain an explicit analytical form.  Advances in computing and the availability of cheap, formidable computing power have helped get around this problem through the use of simulation-based methods such as Markov-chain Monte Carlo (MCMC) \danny{MCMC reference}, a technique that generates a sample from the posterior distribution through simulation from known statistical densities.

% Introduce sequential Monte Carlo
A drawback of MCMC is that when new data become available, the entire analysis needs to be performed again.  That is, samples from the previous analysis cannot be reused and new samples need to be generated, a process that often times requires significant time and computing power.  In fields where data are collected sequentially and need to be analyzed in real time such as tracking an aircraft using radar or monitoring the stock market, this is computationally inefficient.  Sequential Monte Carlo - or particle filtering - methods allow for performing inference on-line by updating the posterior sample as data become available.  Furthermore, these methods are flexible, general, easy to implement, and amenable to computing in parallel.

% Introduce bootstrap filter, degeneracy problem
The first and most basic particle filter - named the bootstrap filter - was developed by \citet{Gord:Salm:Smit:nove:1993}.  The bootstrap filter algorithm samples values of the unknown quantities - or particles - from a prior distribution, propagates the particles forward in time using an evolution equation, calculates weights for each particle using a likelihood function based on the data observed up to that time, resamples the particles to balance out the weights, and then returns to the propagate step and repeats until all the data have been processed.  The problem with this algorithm is mainly in the resampling step, where particles with large weights emit more copies of themselves into the next iteration of the filter while particles with small weights get eliminated.  This can lead to \emph{particle attrition}, or a degeneracy of particles toward one value.  The problem is exacerbated further when one or more of the unknown quantities are held fixed over time, since new values are not generating during propagation.

% Introduce APF, KDPF, more sophisiticated approaches
One way to fight particle degeneracy is by simply increasing the number of particles.  A more efficient way, however, was developed by \citet{Pitt:Shep:filt:1999} called the auxiliary particle filter.  The auxiliary particle filter attempts to avoid degeneracy by sampling particles in areas of higher likelihood by looking ahead at the next data point before resampling.  An even better method, as this paper demonstrates, was developed by \citet{Liu:West:comb:2001}.  Their version of the particle filter distinguishes fixed parameters from unobserved states of the model that evolve over time and refreshes parameter values at each iteration of the filter by sampling from a normal kernel density approximation of posterior distribution of the fixed parameters.  Further improvements to the efficiency of the algorithm include using a measure of nonuniformity of particle weights to determing when to resample, and \danny{references to more sophisticated methods discussed in the last section}

% Introduce epidemiological modeling, Skvortsov Math. Bio. paper

% Introduce layout of paper (see main document)

\bibliographystyle{model1-num-names}
\bibliography{jarad}

\end{document}