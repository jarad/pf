\documentclass{elsarticle}

\usepackage{amsmath}
\usepackage{natbib}
\usepackage{color}
\usepackage{graphicx}
\usepackage{caption}

\graphicspath{{/Users/niemi/Dropbox/SIR_Particle_Filtering/Graphs/}
                       {/Users/niemi/Dropbox/SIR_Particle_Filtering/doesnotexist/}
                       {/Users/Danny/Dropbox/SIR_Particle_Filtering/Graphs/}
                       {/data/home/faculty/meiring/Dropbox/SIR_Particle_Filtering/Graphs/}
                       {./Graphs/}
                       % Add your directories here
}

\newcommand{\jarad}[1]{{\color{red}JARAD: #1}}
\newcommand{\danny}[1]{{\color{blue}DANNY: #1}}

\begin{document}

\noindent {\bf Abstract} \\

This paper reviews sequential Monte Carlo (i.e. particle filtering) methods of estimation and compares the performance of different particle filtering algorithms when applied to a stochastic compartmental model of a disease outbreak.  In addition, we compare different choices of resampling scheme and prior distribution on the unknown, fixed parameter when running the particle filter.  Our results indicate that an algorithm that resamples values of the unknown parameter using a normal kernel density approximation of the posterior performs most efficiently, is best at avoiding particle degeneracy, and enhances our ability to accurately track the evolution of an epidemic over time.

\section{Introduction} \label{sec:intro}

% Introduce Bayesian framework, MCMC
In statistical applications where it is necessary to incorporate prior knowledge of unknown quantities, the Bayesian framework is often convenient for performing statistical analysis.  In this case, all inference is conducted through the posterior distribution of the unknown quantites given the observed data.  However, the calculation of the posterior distribution can involve complicated integrals, and in many situations it is impossible to obtain an explicit analytical form.  Advances in computing and the availability of cheap, formidable computing power have helped get around this problem through the use of simulation-based methods such as Markov-chain Monte Carlo (MCMC) \danny{MCMC reference}, a technique that generates samples from the posterior distribution through simulation from known statistical densities.

% Introduce sequential Monte Carlo
A drawback of MCMC is that when new data become available, the entire analysis needs to be performed again.  That is, samples from the previous analysis cannot be reused and new samples need to be generated, a process that often times requires significant time and computing power.  In fields where data are collected sequentially and need to be analyzed in real time such as tracking an aircraft using radar or monitoring the stock market, this is computationally inefficient.  Sequential Monte Carlo - or particle filtering - methods allow for performing inference on-line by updating the posterior sample as data become available.  Furthermore, these methods are flexible, general, easy to implement, and amenable to computing in parallel.

% Introduce bootstrap filter, degeneracy problem
The first and most basic particle filter - named the bootstrap filter - was developed by \citet{Gord:Salm:Smit:nove:1993}.  The bootstrap filter involves an iterative algorithm that samples values of the unknown quantities - or particles - from a prior distribution, propagates the particles forward in time using an evolution equation, calculates weights for each particle using a likelihood function based on the data observed up to that time, and resamples the particles based on these weights.  The problem with this algorithm is mainly in the resampling step, where particles with large weights emit more copies of themselves into the next iteration of the filter while particles with small weights get eliminated.  This can lead to \emph{particle attrition}, or a degeneracy of particles toward one value.  The problem is exacerbated further when one or more of the unknown quantities are held fixed over time, since, in this case, new values are not generated during propagation.

% Introduce APF, KDPF, more sophisiticated approaches
One way to fight particle degeneracy is by simply increasing the number of particles.  A more efficient way, however, was developed by \citet{Pitt:Shep:filt:1999} called the auxiliary particle filter.  The auxiliary particle filter attempts to avoid degeneracy by sampling particles in areas of higher likelihood by looking ahead at the next data point before resampling.  An algorithm developed by \citet{Liu:West:comb:2001} builds on the auxiliary particle filter by distinguishing fixed parameters from unobserved states that evolve over time.  Their version of the particle filter avoids degeneracy by resampling values from a normal kernel density approximation of the posterior distribution of the fixed parameters.  Further improvements to the efficiency of the algorithm include using a measure of nonuniformity of particle weights to determine when to resample, and \danny{references to more sophisticated methods discussed in the last section}

% Introduce epidemiological modeling, Skvortsov Math. Bio. paper
Epidemiogical modeling is an area where particle filtering can play an important role.  Models of disease outbreaks can be broken into two parts: a dynamic model of how the epidemic evolves and a measurement model of syndromic data.  Thus, it is easy to conceptualize an epidemic from a Bayesian viewpoint as filtering problem using a state-space model.  Since many mechanistic models of disease transmission are nonlinear, sequential Monte Carlo is a natural fit.  \citet{skvortsov2012monitoring} analyzes a simulated epidemic in this way using a stochastic compartmental epidemiological model and shows that an epidemic can be adequately predicted using the bootstrap filter.  In this paper, we show this can be done better and more efficiently using more sophisticated versions of the particle filter.

% Introduce layout of paper (see main document)

\bibliographystyle{model1-num-names}
\bibliography{jarad}

\end{document} 